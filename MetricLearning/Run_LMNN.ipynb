{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Learning - LMNN\n",
    "\n",
    "Underneath you can define the hyperparameters, l, mu and K.\n",
    "* l is the margin parameter\n",
    "* mu is a trade-off parameter between the push and pull in the loss function\n",
    "* K is the number of target neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from Model import get_data\n",
    "\n",
    "l = 1\n",
    "mu = 1\n",
    "K = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* F is the dimensionality of our data. We choose that arbitrarily\n",
    "* L is the linear transformation\n",
    "\n",
    "L is set to be a diagonal matrix of ones to begin with. However, it would be interesting to experiement with other initial L matrices, since the problem is non-convex. We could also try to implement the constrained non-convex version of LMNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 128\n",
    "L = np.eye(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings is: (128, 100)\n",
      "Shape of labels is: (100,) \n",
      "\n",
      "Silhouette Score of data is: 0.2929665148258209\n"
     ]
    }
   ],
   "source": [
    "embeddings, labels = get_data()\n",
    "s_score = sklearn.metrics.silhouette_score(embeddings.T, labels, metric='euclidean')\n",
    "\n",
    "print(\"Shape of embeddings is: {}\".format(np.shape(embeddings)))\n",
    "print(\"Shape of labels is: {} \\n\".format(np.shape(labels)))\n",
    "print(\"Silhouette Score of data is: {}\".format(s_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Plots\n",
    "\n",
    "We should put in some plots of the data here.. We will need that for the presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi square distance, as described in equation (3) in the non-linear metric learning paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_distance(xi, xj):\n",
    "    \"\"\"\n",
    "    Chi square distance\n",
    "\n",
    "    :param xi: Embedding (1, F)\n",
    "    :param xj: Target Neighbor (1, F)\n",
    "    :return: Distance\n",
    "    \"\"\"\n",
    "    return 1/2 * np.sum(np.square(xi - xj) / (xi + xj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function as described in equaltion (5) in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(xi, xj, xk):\n",
    "    \"\"\"\n",
    "    Loss function as described in the paper\n",
    "\n",
    "    :param xi: One embedding        (1, F)\n",
    "    :param xj: K target neighbors   (K, F)\n",
    "    :param xk: Unknown imposters    (?, F)\n",
    "\n",
    "    :return: Loss for one embedding\n",
    "    \"\"\"\n",
    "\n",
    "    _, K = np.shape(xj)\n",
    "    imposter, _ = np.shape(xj)\n",
    "    sum = 0\n",
    "\n",
    "    for j in range(K):\n",
    "        sum += chi_square_distance(L @ xi, L @ xj[:, j])\n",
    "        inner_sum = 0\n",
    "        for k in range(imposter):\n",
    "            inner_sum += max(0, l + chi_square_distance(xi, xj[:, j]) - chi_square_distance(xi, xk[k, :]))\n",
    "        sum += mu * inner_sum\n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to find triples. Distance function need to be changed, to find the distance through the L plane, and not just in the euclidean space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(xi, X):\n",
    "    \"\"\"\n",
    "    :param xi: Embedding vector (1, F)\n",
    "    :param X: Data matrix without embedding vector (N, F)\n",
    "    :return: Distance vector (1, N)\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(((X @ L) - (xi @ L)), axis=1)\n",
    "\n",
    "\n",
    "def find_triplets(xi, yi, X, y):\n",
    "    \"\"\"\n",
    "    Given some vector xi and corresponding label yi, find target neighbors and imposters\n",
    "\n",
    "    :param xi: Embedding vector (1, F)\n",
    "    :param yi: Label for embedding vector\n",
    "    :param X: Full data matrix  (N, F)\n",
    "    :return: target_neighbors and imposters for embedding (K, F) (?, F)\n",
    "    \"\"\"\n",
    "    candidate_target_neighbors = X[np.where(yi == y)]\n",
    "    imposters = X[np.where(yi != y)]\n",
    "\n",
    "    target_neighbors_dist = distance(xi, candidate_target_neighbors)\n",
    "    imposters_dist = distance(xi, imposters)\n",
    "\n",
    "    # Find K target neighbors\n",
    "    target_neighbors = np.zeros((1, F))\n",
    "    for i in range(K):\n",
    "        min_index = np.argmin(target_neighbors_dist)\n",
    "        target_neighbors = np.vstack((target_neighbors, candidate_target_neighbors[min_index]))\n",
    "        candidate_target_neighbors = np.delete(candidate_target_neighbors, (min_index), axis=0)\n",
    "    target_neighbors = target_neighbors[1:, :]\n",
    "\n",
    "    # Find ? imposters\n",
    "    max_target_dist = np.max(target_neighbors_dist)\n",
    "    imposters = imposters[np.where(imposters_dist < max_target_dist + l)]\n",
    "\n",
    "    return target_neighbors, imposters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run LMNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.361904761904762"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO:  Run this in loop over all vectors in X \n",
    "xj, xk = find_triplets(xi, yi, X, Y)\n",
    "loss_function(xi.T, xj.T, xk.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
